{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "from osgeo import gdal, osr, ogr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import statistics\n",
    "from osgeo import osr\n",
    "import math\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = gdal.Open('data\\\\GRIB_air_pollution\\\\adaptor.mars.internal-1685222038.7457314-9629-11-395c9a70-7b6e-4dd0-bc89-1331fd305c05.grib', gdal.GA_ReadOnly)\n",
    "message_count = dataset.RasterCount\n",
    "LAT_LON_CONVERT = 4/3\n",
    "\n",
    "#low-cloud-cover == Particulate matter d < 2.5 µm (PM2.5)\n",
    "#convective-cloud-cover == Particulate matter d < 1 µm (PM1)\n",
    "#medium-cloud-cover == Particulate matter d < 10 µm (PM10)\n",
    "\n",
    "meta_map_dict = {\n",
    "    \"Convective cloud cover [%]\" : \"PM1\",\n",
    "    \"Medium cloud cover [%]\" : \"PM10\",\n",
    "    \"Low cloud cover [%]\" : \"PM2.5\"\n",
    "}\n",
    "\n",
    "#array[lat, lon]\n",
    "\n",
    "\n",
    "def lat_lon_converter(lat, lon):\n",
    "    #latitude +90 -> 0, 0 -> 90, -90 -> 180\n",
    "    #longitude -180 -> 0, 0 -> 180, 180 -> 360\n",
    "    new_lat = round(abs(lat - 90) * LAT_LON_CONVERT)\n",
    "    new_lon = round((lon + 180) * LAT_LON_CONVERT)\n",
    "    return new_lat, new_lon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\\\solar_panel_analysis_dataset_final.csv\")\n",
    "\n",
    "id_list = df[\"GEM phase ID\"].tolist()\n",
    "longitude_list = df[\"Longitude\"].tolist()\n",
    "latitude_list = df[\"Latitude\"].tolist()\n",
    "\n",
    "read_coordinates_dict = {}\n",
    "GRIB_progress = \"\"\n",
    "progress = \"\"\n",
    "\n",
    "for i in range(len(id_list)):\n",
    "    read_coordinates_dict[id_list[i]] = {\"longitude\":longitude_list[i], \"latitude\": latitude_list[i]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_chunks(lst, chunk_size):\n",
    "    return [lst[i:i+chunk_size] for i in range(0, len(lst), chunk_size)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "chunks = create_chunks(list(read_coordinates_dict.keys()), 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-07 08:27:32.779305 - Progress on GRIB processing: 0%\n",
      "2023-06-07 08:28:28.828764 - Progress on GRIB processing: 10%\n",
      "2023-06-07 08:29:17.897929 - Progress on GRIB processing: 20%\n",
      "2023-06-07 08:30:05.427016 - Progress on GRIB processing: 30%\n",
      "2023-06-07 08:30:56.683987 - Progress on GRIB processing: 40%\n",
      "2023-06-07 08:31:46.489871 - Progress on GRIB processing: 50%\n",
      "2023-06-07 08:32:31.262185 - Progress on GRIB processing: 60%\n",
      "2023-06-07 08:33:25.484789 - Progress on GRIB processing: 70%\n",
      "2023-06-07 08:34:07.804374 - Progress on GRIB processing: 80%\n",
      "2023-06-07 08:34:51.031789 - Progress on GRIB processing: 90%\n",
      "2023-06-07 08:35:43.217135 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 08:55:07.520988 - Progress of chunk 4/9: 10%\n",
      "2023-06-07 09:04:29.860108 - Progress of chunk 4/9: 20%\n",
      "2023-06-07 09:14:06.982961 - Progress of chunk 4/9: 30%\n",
      "2023-06-07 09:24:27.800226 - Progress of chunk 4/9: 40%\n",
      "2023-06-07 09:34:07.447128 - Progress of chunk 4/9: 50%\n",
      "2023-06-07 09:43:38.889725 - Progress of chunk 4/9: 60%\n",
      "2023-06-07 09:53:04.196184 - Progress of chunk 4/9: 70%\n",
      "2023-06-07 10:02:33.021841 - Progress of chunk 4/9: 80%\n",
      "2023-06-07 10:12:05.718554 - Progress of chunk 4/9: 90%\n",
      "2023-06-07 10:21:02.741722 - Progress of chunk 4/9: 100%\n",
      "JSON was created for chunk: 4/9\n",
      "2023-06-07 10:21:27.710978 - Progress on GRIB processing: 0%\n",
      "2023-06-07 10:22:21.508500 - Progress on GRIB processing: 10%\n",
      "2023-06-07 10:23:07.810464 - Progress on GRIB processing: 20%\n",
      "2023-06-07 10:23:53.517846 - Progress on GRIB processing: 30%\n",
      "2023-06-07 10:24:38.536598 - Progress on GRIB processing: 40%\n",
      "2023-06-07 10:25:29.325315 - Progress on GRIB processing: 50%\n",
      "2023-06-07 10:26:13.313374 - Progress on GRIB processing: 60%\n",
      "2023-06-07 10:27:02.183227 - Progress on GRIB processing: 70%\n",
      "2023-06-07 10:27:45.490056 - Progress on GRIB processing: 80%\n",
      "2023-06-07 10:28:29.738574 - Progress on GRIB processing: 90%\n",
      "2023-06-07 10:29:20.569664 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 10:39:17.999585 - Progress of chunk 5/9: 0%\n",
      "2023-06-07 10:48:24.317204 - Progress of chunk 5/9: 10%\n",
      "2023-06-07 10:58:28.522922 - Progress of chunk 5/9: 20%\n",
      "2023-06-07 11:08:27.300520 - Progress of chunk 5/9: 30%\n",
      "2023-06-07 11:18:05.051992 - Progress of chunk 5/9: 40%\n",
      "2023-06-07 11:27:10.452034 - Progress of chunk 5/9: 50%\n",
      "2023-06-07 11:36:32.187557 - Progress of chunk 5/9: 60%\n",
      "2023-06-07 11:45:49.794452 - Progress of chunk 5/9: 70%\n",
      "2023-06-07 11:56:24.311167 - Progress of chunk 5/9: 80%\n",
      "2023-06-07 12:05:42.401003 - Progress of chunk 5/9: 90%\n",
      "2023-06-07 12:14:58.323530 - Progress of chunk 5/9: 100%\n",
      "JSON was created for chunk: 5/9\n",
      "2023-06-07 12:15:24.195495 - Progress on GRIB processing: 0%\n",
      "2023-06-07 12:16:13.531904 - Progress on GRIB processing: 10%\n",
      "2023-06-07 12:16:59.900082 - Progress on GRIB processing: 20%\n",
      "2023-06-07 12:17:46.174027 - Progress on GRIB processing: 30%\n",
      "2023-06-07 12:18:32.881422 - Progress on GRIB processing: 40%\n",
      "2023-06-07 12:19:18.179317 - Progress on GRIB processing: 50%\n",
      "2023-06-07 12:20:01.652491 - Progress on GRIB processing: 60%\n",
      "2023-06-07 12:20:49.710825 - Progress on GRIB processing: 70%\n",
      "2023-06-07 12:21:32.039178 - Progress on GRIB processing: 80%\n",
      "2023-06-07 12:22:16.131602 - Progress on GRIB processing: 90%\n",
      "2023-06-07 12:23:06.566083 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 12:33:17.323581 - Progress of chunk 6/9: 0%\n",
      "2023-06-07 12:42:03.775736 - Progress of chunk 6/9: 10%\n",
      "2023-06-07 12:51:15.664977 - Progress of chunk 6/9: 20%\n",
      "2023-06-07 13:00:36.503652 - Progress of chunk 6/9: 30%\n",
      "2023-06-07 13:09:58.811613 - Progress of chunk 6/9: 40%\n",
      "2023-06-07 13:19:11.425053 - Progress of chunk 6/9: 50%\n",
      "2023-06-07 13:28:28.575475 - Progress of chunk 6/9: 60%\n",
      "2023-06-07 13:37:47.863443 - Progress of chunk 6/9: 70%\n",
      "2023-06-07 13:47:08.747606 - Progress of chunk 6/9: 80%\n",
      "2023-06-07 13:56:32.474249 - Progress of chunk 6/9: 90%\n",
      "2023-06-07 14:05:44.750286 - Progress of chunk 6/9: 100%\n",
      "JSON was created for chunk: 6/9\n",
      "2023-06-07 14:06:10.514303 - Progress on GRIB processing: 0%\n",
      "2023-06-07 14:07:03.706631 - Progress on GRIB processing: 10%\n",
      "2023-06-07 14:07:56.584859 - Progress on GRIB processing: 20%\n",
      "2023-06-07 14:08:50.668142 - Progress on GRIB processing: 30%\n",
      "2023-06-07 14:09:45.804871 - Progress on GRIB processing: 40%\n",
      "2023-06-07 14:10:37.721541 - Progress on GRIB processing: 50%\n",
      "2023-06-07 14:11:28.351012 - Progress on GRIB processing: 60%\n",
      "2023-06-07 14:12:23.348246 - Progress on GRIB processing: 70%\n",
      "2023-06-07 14:13:11.536433 - Progress on GRIB processing: 80%\n",
      "2023-06-07 14:14:01.503168 - Progress on GRIB processing: 90%\n",
      "2023-06-07 14:15:01.280391 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 14:26:08.783964 - Progress of chunk 7/9: 0%\n",
      "2023-06-07 14:35:00.885827 - Progress of chunk 7/9: 10%\n",
      "2023-06-07 14:44:21.418560 - Progress of chunk 7/9: 20%\n",
      "2023-06-07 14:53:38.236863 - Progress of chunk 7/9: 30%\n",
      "2023-06-07 15:02:53.561737 - Progress of chunk 7/9: 40%\n",
      "2023-06-07 15:12:05.531429 - Progress of chunk 7/9: 50%\n",
      "2023-06-07 15:21:24.440578 - Progress of chunk 7/9: 60%\n",
      "2023-06-07 15:30:25.818313 - Progress of chunk 7/9: 70%\n",
      "2023-06-07 15:39:44.652473 - Progress of chunk 7/9: 80%\n",
      "2023-06-07 15:48:59.871800 - Progress of chunk 7/9: 90%\n",
      "2023-06-07 15:58:14.878786 - Progress of chunk 7/9: 100%\n",
      "JSON was created for chunk: 7/9\n",
      "2023-06-07 15:58:41.131727 - Progress on GRIB processing: 0%\n",
      "2023-06-07 15:59:34.258198 - Progress on GRIB processing: 10%\n",
      "2023-06-07 16:00:20.867231 - Progress on GRIB processing: 20%\n",
      "2023-06-07 16:01:07.440116 - Progress on GRIB processing: 30%\n",
      "2023-06-07 16:01:53.476325 - Progress on GRIB processing: 40%\n",
      "2023-06-07 16:02:43.434601 - Progress on GRIB processing: 50%\n",
      "2023-06-07 16:03:27.205043 - Progress on GRIB processing: 60%\n",
      "2023-06-07 16:04:13.182824 - Progress on GRIB processing: 70%\n",
      "2023-06-07 16:04:56.661596 - Progress on GRIB processing: 80%\n",
      "2023-06-07 16:05:41.252382 - Progress on GRIB processing: 90%\n",
      "2023-06-07 16:06:31.823693 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 16:17:31.698213 - Progress of chunk 8/9: 0%\n",
      "2023-06-07 16:26:27.366400 - Progress of chunk 8/9: 10%\n",
      "2023-06-07 16:36:27.083793 - Progress of chunk 8/9: 20%\n",
      "2023-06-07 16:45:45.052195 - Progress of chunk 8/9: 30%\n",
      "2023-06-07 16:55:01.932866 - Progress of chunk 8/9: 40%\n",
      "2023-06-07 17:04:21.102198 - Progress of chunk 8/9: 50%\n",
      "2023-06-07 17:13:40.277106 - Progress of chunk 8/9: 60%\n",
      "2023-06-07 17:22:54.428104 - Progress of chunk 8/9: 70%\n",
      "2023-06-07 17:32:20.557858 - Progress of chunk 8/9: 80%\n",
      "2023-06-07 17:41:44.374425 - Progress of chunk 8/9: 90%\n",
      "2023-06-07 17:51:08.089572 - Progress of chunk 8/9: 100%\n",
      "JSON was created for chunk: 8/9\n",
      "2023-06-07 17:51:33.559859 - Progress on GRIB processing: 0%\n",
      "2023-06-07 17:52:22.255374 - Progress on GRIB processing: 10%\n",
      "2023-06-07 17:53:07.177141 - Progress on GRIB processing: 20%\n",
      "2023-06-07 17:53:50.550309 - Progress on GRIB processing: 30%\n",
      "2023-06-07 17:54:36.533046 - Progress on GRIB processing: 40%\n",
      "2023-06-07 17:55:24.314737 - Progress on GRIB processing: 50%\n",
      "2023-06-07 17:56:09.641754 - Progress on GRIB processing: 60%\n",
      "2023-06-07 17:56:54.450813 - Progress on GRIB processing: 70%\n",
      "2023-06-07 17:57:32.368657 - Progress on GRIB processing: 80%\n",
      "2023-06-07 17:58:11.472585 - Progress on GRIB processing: 90%\n",
      "2023-06-07 17:58:56.339961 - Progress on GRIB processing: 100%\n",
      "Statistical processing of GRIB file is finished!\n",
      "2023-06-07 18:07:14.837693 - Progress of chunk 9/9: 0%\n",
      "2023-06-07 18:14:26.100894 - Progress of chunk 9/9: 10%\n",
      "2023-06-07 18:22:02.153515 - Progress of chunk 9/9: 20%\n",
      "2023-06-07 18:29:38.635883 - Progress of chunk 9/9: 30%\n",
      "2023-06-07 18:37:18.573375 - Progress of chunk 9/9: 40%\n",
      "2023-06-07 18:44:39.889629 - Progress of chunk 9/9: 50%\n",
      "2023-06-07 18:51:59.493494 - Progress of chunk 9/9: 60%\n",
      "2023-06-07 18:59:23.472830 - Progress of chunk 9/9: 70%\n",
      "2023-06-07 19:06:44.958498 - Progress of chunk 9/9: 80%\n",
      "2023-06-07 19:14:15.004693 - Progress of chunk 9/9: 90%\n",
      "2023-06-07 19:22:03.109745 - Progress of chunk 9/9: 100%\n",
      "JSON was created for chunk: 9/9\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[3:]:\n",
    "\n",
    "    final_dict = {}\n",
    "\n",
    "    for band in range(1, dataset.RasterCount):\n",
    "        current_GRIB_progress = round((band/dataset.RasterCount) * 100)\n",
    "        if current_GRIB_progress % 10 == 0 and current_GRIB_progress != GRIB_progress:\n",
    "            print(\"{} - Progress on GRIB processing: {}%\".format(datetime.now(),current_GRIB_progress))\n",
    "            GRIB_progress = current_GRIB_progress\n",
    "\n",
    "        meta = dataset.GetRasterBand(band).GetMetadata()\n",
    "        particulate = meta_map_dict[meta['GRIB_COMMENT']]\n",
    "        date = datetime.utcfromtimestamp(int(meta['GRIB_REF_TIME']))\n",
    "        year = date.strftime('%Y')\n",
    "        month = date.strftime('%m')\n",
    "        raster = dataset.GetRasterBand(band)\n",
    "        array = raster.ReadAsArray()\n",
    "        scaled_array = array * 1000000000\n",
    "\n",
    "        for ids in chunk:\n",
    "            scaled_lat,scaled_lon = lat_lon_converter(read_coordinates_dict[ids][\"latitude\"],read_coordinates_dict[ids][\"longitude\"])\n",
    "\n",
    "\n",
    "            if ids not in final_dict:\n",
    "                final_dict[ids] = {}\n",
    "                final_dict[ids][\"monthly\"] = {}\n",
    "                final_dict[ids][\"yearly\"] = {}\n",
    "                final_dict[ids][\"full\"] = {}\n",
    "\n",
    "            if month not in final_dict[ids][\"monthly\"]:\n",
    "                final_dict[ids][\"monthly\"][month] = {}\n",
    "\n",
    "            if year not in final_dict[ids][\"yearly\"]:\n",
    "                final_dict[ids][\"yearly\"][year] = {}\n",
    "\n",
    "            if particulate in final_dict[ids][\"monthly\"][month].keys():\n",
    "                final_dict[ids][\"monthly\"][month][particulate].append(scaled_array[scaled_lat,scaled_lon])\n",
    "            else:\n",
    "                final_dict[ids][\"monthly\"][month][particulate] = [scaled_array[scaled_lat,scaled_lon]]\n",
    "\n",
    "\n",
    "            if particulate in final_dict[ids][\"yearly\"][year].keys():\n",
    "                final_dict[ids][\"yearly\"][year][particulate].append(scaled_array[scaled_lat,scaled_lon])\n",
    "            else:\n",
    "                final_dict[ids][\"yearly\"][year][particulate] = [scaled_array[scaled_lat,scaled_lon]]\n",
    "\n",
    "\n",
    "            if particulate in final_dict[ids][\"full\"].keys():\n",
    "                final_dict[ids][\"full\"][particulate].append(scaled_array[scaled_lat,scaled_lon])\n",
    "            else:\n",
    "                final_dict[ids][\"full\"][particulate] = [scaled_array[scaled_lat,scaled_lon]]\n",
    "\n",
    "    for ids, weather_values in final_dict.items():\n",
    "        for date, param_values in weather_values.items():\n",
    "            for date_key, values in param_values.items():\n",
    "                if date == \"full\":\n",
    "                    values = param_values\n",
    "                for particulate in ['PM10', 'PM1', 'PM2.5']:\n",
    "                    parameter_sum = sum(values[particulate])\n",
    "                    parameter_count = len(values[particulate])\n",
    "                    average_parameter = parameter_sum/parameter_count\n",
    "                    median_parameter = statistics.median(values[particulate])\n",
    "                    mode_parameter = statistics.mode(values[particulate])\n",
    "                    stdev_parameter = statistics.stdev(values[particulate])\n",
    "                    variance_parameter = statistics.variance(values[particulate])\n",
    "                    max_parameter = max(values[particulate])\n",
    "                    min_parameter = min(values[particulate])\n",
    "                    range_parameter = max_parameter - min_parameter\n",
    "                    values[particulate] = {\"average\": average_parameter, \"median\": median_parameter, \"mode\": mode_parameter, \"standard_deviation\": stdev_parameter, \"variance\": variance_parameter, \"max\": max_parameter, \"min\": min_parameter, \"range\": range_parameter}\n",
    "                if date == \"full\":\n",
    "                    break\n",
    "    print(\"{} - Statistical processing of GRIB file is finished!\".format(datetime.now()))\n",
    "\n",
    "    for ids in chunk:\n",
    "        monthly_averages = {}\n",
    "        yearly_averages = {}\n",
    "        full_averages = {}\n",
    "\n",
    "        response = requests.get(\n",
    "            \"https://archive-api.open-meteo.com/v1/archive?\",\n",
    "            params={\n",
    "                \"latitude\": read_coordinates_dict[ids][\"latitude\"],\n",
    "                \"longitude\": read_coordinates_dict[ids][\"longitude\"],\n",
    "                \"start_date\": \"2005-01-01\",\n",
    "                \"end_date\": \"2015-12-31\",\n",
    "                \"hourly\": \"relativehumidity_2m,dewpoint_2m,precipitation,cloudcover,shortwave_radiation\"\n",
    "            }\n",
    "        )\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        for date, hum, dewp, precip, cloud, rad in zip(data[\"hourly\"][\"time\"],data[\"hourly\"][\"relativehumidity_2m\"], data[\"hourly\"][\"dewpoint_2m\"], data[\"hourly\"][\"precipitation\"], data[\"hourly\"][\"cloudcover\"], data[\"hourly\"][\"shortwave_radiation\"]):\n",
    "            date_format = datetime.strptime(date, '%Y-%m-%dT%H:%M')\n",
    "            year = date_format.strftime('%Y')\n",
    "            month = date_format.strftime('%m')\n",
    "            parameter_dict = {'relativehumidity_2m': hum, \"dewpoint_2m\": dewp, \"precipitation\": precip, \"cloudcover\": cloud, \"shortwave_radiation\" : rad}\n",
    "\n",
    "            if month not in monthly_averages:\n",
    "                monthly_averages[month] = {}\n",
    "\n",
    "            if year not in yearly_averages:\n",
    "                yearly_averages[year] = {}\n",
    "\n",
    "            for items, parameter_values in parameter_dict.items():\n",
    "                if items in monthly_averages[month].keys():\n",
    "                    monthly_averages[month][items].append(parameter_values)\n",
    "                else:\n",
    "                    monthly_averages[month][items] = [parameter_values]\n",
    "\n",
    "\n",
    "                if items in yearly_averages[year].keys():\n",
    "                    yearly_averages[year][items].append(parameter_values)\n",
    "                else:\n",
    "                    yearly_averages[year][items] = [parameter_values]\n",
    "\n",
    "\n",
    "                if items in full_averages.keys():\n",
    "                    full_averages[items].append(parameter_values)\n",
    "                else:\n",
    "                    full_averages[items] = [parameter_values]\n",
    "\n",
    "        parameter_list = list(parameter_dict.keys())\n",
    "\n",
    "        for date_list in [yearly_averages, monthly_averages, full_averages]:\n",
    "            for date, values in date_list.items():\n",
    "                if date_list == full_averages:\n",
    "                    values = full_averages\n",
    "                for particulate in parameter_list:\n",
    "                    parameter_sum = sum(values[particulate])\n",
    "                    parameter_count = len(values[particulate])\n",
    "                    average_parameter = parameter_sum/parameter_count\n",
    "                    median_parameter = statistics.median(values[particulate])\n",
    "                    mode_parameter = statistics.mode(values[particulate])\n",
    "                    stdev_parameter = statistics.stdev(values[particulate])\n",
    "                    variance_parameter = statistics.variance(values[particulate])\n",
    "                    max_parameter = max(values[particulate])\n",
    "                    min_parameter = min(values[particulate])\n",
    "                    range_parameter = max_parameter - min_parameter\n",
    "                    values[particulate] = {\"average\": average_parameter, \"median\": median_parameter, \"mode\": mode_parameter, \"standard_deviation\": stdev_parameter, \"variance\": variance_parameter, \"max\": max_parameter, \"min\": min_parameter, \"range\": range_parameter}\n",
    "                if date_list == full_averages:\n",
    "                    break\n",
    "\n",
    "        for month in monthly_averages.keys():\n",
    "            final_dict[ids][\"monthly\"][month].update(monthly_averages[month])\n",
    "\n",
    "        for year in yearly_averages.keys():\n",
    "            final_dict[ids][\"yearly\"][year].update(yearly_averages[year])\n",
    "\n",
    "        final_dict[ids][\"full\"].update(full_averages)\n",
    "\n",
    "        current_progress = round((chunk.index(ids)/len(chunk)) * 100)\n",
    "        if current_progress % 10 == 0 and current_progress != progress:\n",
    "            print(\"{} - Progress of chunk {}/{}: {}%\".format(datetime.now(),chunks.index(chunk) + 1, len(chunks), current_progress))\n",
    "            progress = current_progress\n",
    "\n",
    "    with open('additional_weather_data\\\\additional_weather_data_{}.json'.format(chunks.index(chunk) + 1), 'w') as json_file:\n",
    "        json.dump(final_dict, json_file)\n",
    "    print('JSON was created for chunk: {}/{}'.format(chunks.index(chunk) + 1, len(chunks)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
